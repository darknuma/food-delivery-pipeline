{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/__init__.py:58\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m filterwarnings\n\u001b[1;32m     54\u001b[0m filterwarnings(\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistutils Version classes are deprecated. Use packaging.version instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkConf\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RDD, RDDBarrier\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkFiles\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/conf.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Tuple, cast, overload\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjava_gateway\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JVMView, JavaObject\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PySparkRuntimeError\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSparkConf\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py4j'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"FoodDeliveryETL\") \\\n",
    "#     .config(\"spark.jars.packages\", \n",
    "#             \"org.apache.hadoop:hadoop-aws:3.3.6,net.snowflake:spark-snowflake_2.13:3.10\") \\\n",
    "#     .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "#     .config(\"spark.hadoop.fs.s3a.access.key\", os.getenv(\"AWS_ACCESS_KEY\")) \\\n",
    "#     .config(\"spark.hadoop.fs.s3a.secret.key\", os.getenv(\"AWS_SECRET_KEY\")) \\\n",
    "#     .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FoodDeliveryETL\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.6,net.snowflake:spark-snowflake_2.13:3.1.0\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.getenv(\"AWS_ACCESS_KEY\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.getenv(\"AWS_SECRET_KEY\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# spark = SparkSession.bui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_timestamp: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- merchant_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- service_type: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- item_id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- quantity: long (nullable = true)\n",
      " |    |    |-- unit_price: string (nullable = true)\n",
      " |    |    |-- total_price: string (nullable = true)\n",
      " |-- delivery_location: struct (nullable = true)\n",
      " |    |-- latitude: double (nullable = true)\n",
      " |    |-- longitude: double (nullable = true)\n",
      " |    |-- address: string (nullable = true)\n",
      " |-- delivery_fee: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- estimated_delivery_time: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"event_timestamp\", F.to_timestamp(df[\"event_timestamp\"], \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df = df.withColumn(\"delivery_fee\",  df[\"delivery_fee\"].cast(FloatType()))\\\n",
    "        .withColumn(\"total_amount\", df[\"total_amount\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"estimated_delivery_time\", F.to_timestamp(df[\"estimated_delivery_time\"], \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_timestamp: timestamp (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- merchant_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- service_type: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- item_id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- quantity: long (nullable = true)\n",
      " |    |    |-- unit_price: string (nullable = true)\n",
      " |    |    |-- total_price: string (nullable = true)\n",
      " |-- delivery_location: struct (nullable = true)\n",
      " |    |-- latitude: double (nullable = true)\n",
      " |    |-- longitude: double (nullable = true)\n",
      " |    |-- address: string (nullable = true)\n",
      " |-- delivery_fee: float (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- estimated_delivery_time: timestamp (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------+-----------+--------+----------+-----------+\n",
      "|order_id                            |item_id|name       |quantity|unit_price|total_price|\n",
      "+------------------------------------+-------+-----------+--------+----------+-----------+\n",
      "|8d090ee5-a8c3-405f-aee0-afc7b28f162f|item_3 |Menu Item 3|3       |4985.0    |14955.0    |\n",
      "|8d090ee5-a8c3-405f-aee0-afc7b28f162f|item_4 |Menu Item 4|1       |1479.0    |1479.0     |\n",
      "|b17c605f-a93c-4c23-a7e9-9771e962bf08|item_5 |Menu Item 5|1       |4533.0    |4533.0     |\n",
      "|b17c605f-a93c-4c23-a7e9-9771e962bf08|item_4 |Menu Item 4|3       |3833.0    |11499.0    |\n",
      "|b17c605f-a93c-4c23-a7e9-9771e962bf08|item_2 |Menu Item 2|2       |2076.0    |4152.0     |\n",
      "+------------------------------------+-------+-----------+--------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_exploded = df.select(\"order_id\", F.explode(\"items\").alias(\"item\"))\n",
    "\n",
    "# Now, select specific nested fields from the exploded 'item' struct\n",
    "df_exploded.select(\n",
    "    \"order_id\", \n",
    "    \"item.item_id\", \n",
    "    \"item.name\", \n",
    "    \"item.quantity\", \n",
    "    \"item.unit_price\", \n",
    "    \"item.total_price\"\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- item: struct (nullable = true)\n",
      " |    |-- item_id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- quantity: long (nullable = true)\n",
      " |    |-- unit_price: string (nullable = true)\n",
      " |    |-- total_price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exploded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `delivery_location`.`latitude` cannot be resolved. Did you mean one of the following? [`delivery_latitude`, `delivery_longitude`, `delivery_time_minutes`, `delivery_fee`, `event_timestamp`].;\n'Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#422, 'delivery_location.latitude AS delivery_latitude#441, delivery_longitude#277, delivery_time_minutes#312, is_delayed#330]\n+- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, to_date(event_timestamp#183, Some(yyyy-MM-dd), Some(Etc/UTC), false) AS event_date#422, delivery_latitude#259, delivery_longitude#277, delivery_time_minutes#312, is_delayed#330]\n   +- Filter ((isnotnull(order_id#2) AND isnotnull(merchant_id#3)) AND (total_amount#213 > cast(0 as double)))\n      +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277, delivery_time_minutes#312, CASE WHEN (delivery_time_minutes#312 > cast(45 as double)) THEN true ELSE false END AS is_delayed#330]\n         +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277, round((cast((unix_timestamp(estimated_delivery_time#228, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false) - unix_timestamp(event_timestamp#183, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false)) as double) / cast(60 as double)), 0) AS delivery_time_minutes#312]\n            +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277]\n               +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_location#8.longitude AS delivery_longitude#277]\n                  +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_location#8.latitude AS delivery_latitude#259]\n                     +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, date_format(event_timestamp#183, yyyy-MM-dd, Some(Etc/UTC)) AS event_date#243]\n                        +- Filter ((isnotnull(order_id#2) AND isnotnull(merchant_id#3)) AND (total_amount#213 > cast(0 as double)))\n                           +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, to_timestamp(estimated_delivery_time#11, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false) AS estimated_delivery_time#228, payment_method#12, payment_status#13]\n                              +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, cast(total_amount#10 as double) AS total_amount#213, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                 +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, cast(delivery_fee#9 as float) AS delivery_fee#198, total_amount#10, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                    +- Project [event_id#0, to_timestamp(event_timestamp#1, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false) AS event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#9, total_amount#10, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                       +- Relation [event_id#0,event_timestamp#1,order_id#2,merchant_id#3,customer_id#4,service_type#5,order_status#6,items#7,delivery_location#8,delivery_fee#9,total_amount#10,estimated_delivery_time#11,payment_method#12,payment_status#13] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNotNull() \u001b[38;5;241m&\u001b[39m F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNotNull() \u001b[38;5;241m&\u001b[39m (F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mto_date(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myyyy-MM-dd\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelivery_latitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelivery_location.latitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_longitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_location.longitude\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \\\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_location\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_time_minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m                     F\u001b[38;5;241m.\u001b[39mround((F\u001b[38;5;241m.\u001b[39munix_timestamp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimated_delivery_time\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \n\u001b[1;32m      8\u001b[0m                             F\u001b[38;5;241m.\u001b[39munix_timestamp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_delayed\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mwhen(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_time_minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m45\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/dataframe.py:5176\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5173\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5174\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5175\u001b[0m     )\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `delivery_location`.`latitude` cannot be resolved. Did you mean one of the following? [`delivery_latitude`, `delivery_longitude`, `delivery_time_minutes`, `delivery_fee`, `event_timestamp`].;\n'Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#422, 'delivery_location.latitude AS delivery_latitude#441, delivery_longitude#277, delivery_time_minutes#312, is_delayed#330]\n+- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, to_date(event_timestamp#183, Some(yyyy-MM-dd), Some(Etc/UTC), false) AS event_date#422, delivery_latitude#259, delivery_longitude#277, delivery_time_minutes#312, is_delayed#330]\n   +- Filter ((isnotnull(order_id#2) AND isnotnull(merchant_id#3)) AND (total_amount#213 > cast(0 as double)))\n      +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277, delivery_time_minutes#312, CASE WHEN (delivery_time_minutes#312 > cast(45 as double)) THEN true ELSE false END AS is_delayed#330]\n         +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277, round((cast((unix_timestamp(estimated_delivery_time#228, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false) - unix_timestamp(event_timestamp#183, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false)) as double) / cast(60 as double)), 0) AS delivery_time_minutes#312]\n            +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_longitude#277]\n               +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_latitude#259, delivery_location#8.longitude AS delivery_longitude#277]\n                  +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, event_date#243, delivery_location#8.latitude AS delivery_latitude#259]\n                     +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, estimated_delivery_time#228, payment_method#12, payment_status#13, date_format(event_timestamp#183, yyyy-MM-dd, Some(Etc/UTC)) AS event_date#243]\n                        +- Filter ((isnotnull(order_id#2) AND isnotnull(merchant_id#3)) AND (total_amount#213 > cast(0 as double)))\n                           +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, total_amount#213, to_timestamp(estimated_delivery_time#11, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false) AS estimated_delivery_time#228, payment_method#12, payment_status#13]\n                              +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#198, cast(total_amount#10 as double) AS total_amount#213, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                 +- Project [event_id#0, event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, cast(delivery_fee#9 as float) AS delivery_fee#198, total_amount#10, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                    +- Project [event_id#0, to_timestamp(event_timestamp#1, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false) AS event_timestamp#183, order_id#2, merchant_id#3, customer_id#4, service_type#5, order_status#6, items#7, delivery_location#8, delivery_fee#9, total_amount#10, estimated_delivery_time#11, payment_method#12, payment_status#13]\n                                       +- Relation [event_id#0,event_timestamp#1,order_id#2,merchant_id#3,customer_id#4,service_type#5,order_status#6,items#7,delivery_location#8,delivery_fee#9,total_amount#10,estimated_delivery_time#11,payment_method#12,payment_status#13] parquet\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(F.col(\"order_id\").isNotNull() & F.col(\"merchant_id\").isNotNull() & (F.col(\"total_amount\") > 0))\n",
    "df = df.withColumn(\"event_date\", F.to_date(\"event_timestamp\", \"yyyyMMdd\"))\n",
    "df = df.withColumn(\"delivery_latitude\", F.col(\"delivery_location.latitude\")) \\\n",
    "        .withColumn(\"delivery_longitude\", F.col(\"delivery_location.longitude\")) \\\n",
    "        .drop(\"delivery_location\")\n",
    "df = df.withColumn(\"delivery_time_minutes\", \n",
    "                    F.round((F.unix_timestamp(\"estimated_delivery_time\") - \n",
    "                            F.unix_timestamp(\"event_timestamp\")) / 60))\n",
    "df = df.withColumn(\"is_delayed\", F.when(F.col(\"delivery_time_minutes\") > 45, True).otherwise(False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"event_date\", F.to_date(\"event_timestamp\", \"yyyyMMdd\"))\n",
    "df=df.withColumn('event_date', df['event_timestamp'].cast(DateType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"event_date\", F.to_date(\"event_timestamp\", \"yyyyMMdd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_timestamp: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- merchant_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- service_type: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- item_id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- quantity: long (nullable = true)\n",
      " |    |    |-- unit_price: string (nullable = true)\n",
      " |    |    |-- total_price: string (nullable = true)\n",
      " |-- delivery_location: struct (nullable = true)\n",
      " |    |-- latitude: double (nullable = true)\n",
      " |    |-- longitude: double (nullable = true)\n",
      " |    |-- address: string (nullable = true)\n",
      " |-- delivery_fee: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- estimated_delivery_time: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://numa-delivery/bronze/food-delivery-orders-raw/2025/02/05/07/5254.parquet\")\n",
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"event_timestamp\", F.to_timestamp(\"event_timestamp\", \"yyyy-MM-dd HH:mm:ss.SSSSSS\"))\n",
    "df = df.withColumn(\"event_date_parsed\", F.to_date(\"event_timestamp_parsed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"event_date\", F.to_date(\"event_timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"estimated_delivery_time\", F.to_timestamp(\"estimated_delivery_time\", \"yyyy-MM-dd HH:mm:ss.SSSSSS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"delivery_time_minutes\", \n",
    "                    F.round((F.unix_timestamp(\"estimated_delivery_time\") - \n",
    "                            F.unix_timestamp(\"event_timestamp\")) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|event_date|\n",
      "+----------+\n",
      "|2025-02-05|\n",
      "+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('event_date').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = StructType([\n",
    "        StructField(\"event_id\", StringType()),\n",
    "        StructField(\"event_timestamp\", TimestampType()),\n",
    "        StructField(\"order_id\", StringType()),\n",
    "        StructField(\"merchant_id\", StringType()),\n",
    "        StructField(\"customer_id\", StringType()),\n",
    "        StructField(\"service_type\", StringType()),\n",
    "        StructField(\"order_status\", StringType()),\n",
    "        StructField(\"items\", ArrayType(StructType([\n",
    "            StructField(\"item_id\", StringType()),\n",
    "            StructField(\"name\", StringType()),\n",
    "            StructField(\"quantity\", IntegerType()),\n",
    "            StructField(\"unit_price\", FloatType()),\n",
    "            StructField(\"total_price\", FloatType())\n",
    "        ]))),\n",
    "        StructField(\"delivery_location\", StructType([\n",
    "            StructField(\"latitude\", DoubleType()),\n",
    "            StructField(\"longitude\", DoubleType()),\n",
    "            StructField(\"address\", StringType())\n",
    "        ])),\n",
    "        StructField(\"delivery_fee\", FloatType()),\n",
    "        StructField(\"total_amount\", FloatType()),\n",
    "        StructField(\"estimated_delivery_time\", TimestampType()),\n",
    "        StructField(\"payment_method\", StringType()),\n",
    "        StructField(\"payment_status\", StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates_in_bronze():\n",
    "    \"\"\"\n",
    "    Function to generate list of available dates in the bronze layer\n",
    "    \"\"\"\n",
    "    start_date = datetime.date(2025, 2, 1)  # Change to your start date\n",
    "    end_date = datetime.date.today()\n",
    "    \n",
    "    date_list = []\n",
    "    while start_date <= end_date:\n",
    "        date_list.append(start_date.strftime(\"%Y/%m/%d\"))\n",
    "        start_date += datetime.timedelta(days=1)\n",
    "\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_s3_bronze_path = \"s3a://numa-delivery/bronze/food-delivery-orders-raw\"\n",
    "s3_silver_orders_path = \"s3a://numa-delivery/silver/food-delivery-orders/\"\n",
    "s3_silver_items_path = \"s3a://numa-delivery/silver/food-delivery-order_items/\"\n",
    "\n",
    "date_list = get_dates_in_bronze()\n",
    "\n",
    "for date in date_list:\n",
    "    s3_bronze_path = f\"{base_s3_bronze_path}/{date}/*\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Processing data for date: {date}\")\n",
    "        bronze_df = read_bronze_data(s3_bronze_path)\n",
    "        \n",
    "        if bronze_df.count() == 0:\n",
    "            logger.info(f\"No data found for {date}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        silver_df = transform_to_silver(bronze_df)\n",
    "        order_items_df = explode_order_items(silver_df)\n",
    "        \n",
    "        write_silver_data(silver_df, s3_silver_orders_path)\n",
    "        write_order_items(order_items_df, s3_silver_items_path)\n",
    "        \n",
    "        write_to_snowflake(silver_df, \"ORDER\")\n",
    "        write_to_snowflake(order_items_df, \"ORDER_ITEMS\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {date}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o36.parquet.\n: java.lang.NoClassDefFoundError: scala/$less$colon$less\n\tat net.snowflake.spark.snowflake.DefaultSource.shortName(DefaultSource.scala:40)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$2(DataSource.scala:629)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$2$adapted(DataSource.scala:629)\n\tat scala.collection.TraversableLike.$anonfun$filterImpl$1(TraversableLike.scala:304)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:303)\n\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n\tat scala.collection.AbstractTraversable.filterImpl(Traversable.scala:108)\n\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:108)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:629)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: scala.$less$colon$less\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\t... 32 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3a://numa-delivery/bronze/food-delivery-orders-raw/2025/02/05/07/5254.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mprintSchema() \n",
      "File \u001b[0;32m~/projects/food_delivery/venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:544\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    533\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    535\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    536\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/food_delivery/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/projects/food_delivery/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/projects/food_delivery/venv/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o36.parquet.\n: java.lang.NoClassDefFoundError: scala/$less$colon$less\n\tat net.snowflake.spark.snowflake.DefaultSource.shortName(DefaultSource.scala:40)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$2(DataSource.scala:629)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$2$adapted(DataSource.scala:629)\n\tat scala.collection.TraversableLike.$anonfun$filterImpl$1(TraversableLike.scala:304)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:303)\n\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n\tat scala.collection.AbstractTraversable.filterImpl(Traversable.scala:108)\n\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:108)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:629)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: scala.$less$colon$less\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\t... 32 more\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://numa-delivery/bronze/food-delivery-orders-raw/2025/02/05/07/5254.parquet\")\n",
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_s3_bronze_path = \"s3a://numa-delivery/bronze/food-delivery-orders-raw\"\n",
    "s3_silver_orders_path = \"s3a://numa-delivery/silver/food-delivery-orders/\"\n",
    "s3_silver_items_path = \"s3a://numa-delivery/silver/food-delivery-order_items/\"\n",
    "\n",
    "date_list = get_dates_in_bronze()\n",
    "\n",
    "for date in date_list:\n",
    "    s3_bronze_path = f\"{base_s3_bronze_path}/{date}/*\"\n",
    "    \n",
    "    logger.info(f\"Processing data for date: {date}\")\n",
    "    bronze_df = spark.parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orders_schema():\n",
    "    return StructType([\n",
    "        StructField(\"event_id\", StringType()),\n",
    "        StructField(\"event_timestamp\", TimestampType()),\n",
    "        StructField(\"order_id\", StringType()),\n",
    "        StructField(\"merchant_id\", StringType()),\n",
    "        StructField(\"customer_id\", StringType()),\n",
    "        StructField(\"service_type\", StringType()),\n",
    "        StructField(\"order_status\", StringType()),\n",
    "        StructField(\"items\", ArrayType(StructType([\n",
    "            StructField(\"item_id\", StringType()),\n",
    "            StructField(\"name\", StringType()),\n",
    "            StructField(\"quantity\", IntegerType()),\n",
    "            StructField(\"unit_price\", FloatType()),\n",
    "            StructField(\"total_price\", FloatType())\n",
    "        ]))),\n",
    "        StructField(\"delivery_location\", StructType([\n",
    "            StructField(\"latitude\", DoubleType()),\n",
    "            StructField(\"longitude\", DoubleType()),\n",
    "            StructField(\"address\", StringType())\n",
    "        ])),\n",
    "        StructField(\"delivery_fee\", FloatType()),\n",
    "        StructField(\"total_amount\", FloatType()),\n",
    "        StructField(\"estimated_delivery_time\", TimestampType()),\n",
    "        StructField(\"payment_method\", StringType()),\n",
    "        StructField(\"payment_status\", StringType())\n",
    "    ])\n",
    "\n",
    "def read_bronze_data(s3_path):\n",
    "    logger.info(f\"Reading data from {s3_path}\")\n",
    "    return spark.read.schema(get_orders_schema()).parquet(s3_path)\n",
    "\n",
    "def transform_to_silver(df):\n",
    "    df = df.filter(F.col(\"order_id\").isNotNull() & F.col(\"merchant_id\").isNotNull() & (F.col(\"total_amount\") > 0))\n",
    "    df = df.withColumn(\"event_date\", F.date_format(\"event_timestamp\", \"yyyy-MM-dd\"))\n",
    "    df = df.withColumn(\"delivery_latitude\", F.col(\"delivery_location.latitude\")) \\\n",
    "           .withColumn(\"delivery_longitude\", F.col(\"delivery_location.longitude\")) \\\n",
    "           .drop(\"delivery_location\")\n",
    "    df = df.withColumn(\"delivery_time_minutes\", \n",
    "                       F.round((F.unix_timestamp(\"estimated_delivery_time\") - \n",
    "                                F.unix_timestamp(\"event_timestamp\")) / 60))\n",
    "    df = df.withColumn(\"is_delayed\", F.when(F.col(\"delivery_time_minutes\") > 45, True).otherwise(False))\n",
    "    return df\n",
    "\n",
    "def explode_order_items(df):\n",
    "    return df.select(\"order_id\", F.explode(\"items\").alias(\"item\"))\\\n",
    "        .select(\"order_id\", \"item.item_id\", \"item.name\", \"item.quantity\", \"item.unit_price\", \"item.total_price\")\n",
    "\n",
    "def write_silver_data(df, s3_path):\n",
    "    logger.info(f\"Writing data to {s3_path}\")\n",
    "    df.write.partitionBy(\"event_date\").mode(\"append\").parquet(s3_path)\n",
    "\n",
    "def write_order_items(df, s3_path):\n",
    "    df.write.mode(\"append\").parquet(s3_path)\n",
    "\n",
    "def write_to_snowflake(df, table_name):\n",
    "    sf_options = {\n",
    "        \"sfUrl\": \"https://fg00255.switzerland-north.azure.snowflakecomputing.com\",\n",
    "        \"sfUser\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "        \"sfPassword\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "        \"sfDatabase\": \"DELIVERY\",\n",
    "        \"sfSchema\": \"SILVER\",\n",
    "        \"sfWarehouse\": \"COMPUTE_WH\"\n",
    "    }\n",
    "    logger.info(f\"Writing data to Snowflake table: {table_name}\")\n",
    "    df.write.format(\"net.snowflake.spark.snowflake\").options(**sf_options).option(\"dbtable\", table_name).mode(\"append\").save()\n",
    "\n",
    "def get_dates_in_bronze():\n",
    "    \"\"\"\n",
    "    Function to generate list of available dates in the bronze layer\n",
    "    \"\"\"\n",
    "    start_date = datetime.date(2025, 2, 1)  # Change to your start date\n",
    "    end_date = datetime.date.today()\n",
    "    \n",
    "    date_list = []\n",
    "    while start_date <= end_date:\n",
    "        date_list.append(start_date.strftime(\"%Y/%m/%d\"))\n",
    "        start_date += datetime.timedelta(days=1)\n",
    "\n",
    "    return date_list\n",
    "\n",
    "def process_data_for_each_day():\n",
    "    base_s3_bronze_path = \"s3a://numa-delivery/bronze/food-delivery-orders-raw\"\n",
    "    s3_silver_orders_path = \"s3a://numa-delivery/silver/food-delivery-orders/\"\n",
    "    s3_silver_items_path = \"s3a://numa-delivery/silver/food-delivery-order_items/\"\n",
    "    \n",
    "    date_list = get_dates_in_bronze()\n",
    "    \n",
    "    for date in date_list:\n",
    "        s3_bronze_path = f\"{base_s3_bronze_path}/{date}/*\"\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"Processing data for date: {date}\")\n",
    "            bronze_df = read_bronze_data(s3_bronze_path)\n",
    "            \n",
    "            if bronze_df.count() == 0:\n",
    "                logger.info(f\"No data found for {date}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            silver_df = transform_to_silver(bronze_df)\n",
    "            order_items_df = explode_order_items(silver_df)\n",
    "            \n",
    "            write_silver_data(silver_df, s3_silver_orders_path)\n",
    "            write_order_items(order_items_df, s3_silver_items_path)\n",
    "            \n",
    "            write_to_snowflake(silver_df, \"ORDER\")\n",
    "            write_to_snowflake(order_items_df, \"ORDER_ITEMS\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {date}: {e}\")\n",
    "\n",
    "def main():\n",
    "    process_data_for_each_day()\n",
    "    spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
